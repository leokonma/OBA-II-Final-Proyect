# ==== 7) Función wrapper para algoritmos ====
objective_numeric <- function(route, graph, PT, S0, demand, surplus,
minutes_per_block = 2, cost_per_min_eur = 0.6,
penalty_per_unit = 0.5) {
res <- objective_distance_extended(route, graph, PT, S0, demand, surplus,
minutes_per_block, cost_per_min_eur, penalty_per_unit)
return(res$distance_blocks)
}
# ==== 8) Visualizar red base ====
plot_network_time(g, PT = PT, coords = coords,
main = "Distribution network — edges weighted by estimated time (min)")
plot_network(g, PT = PT, demand = d, surplus = s, coords = coords,
main = "Distribution network — optimization by distance (blocks)")
# ==== 9) Ejecutar algoritmos ====
results <- run_all_algorithms(
outer_abbr,
FUN = function(route, ...) objective_numeric(route, graph=g, PT=PT, S0=S0, demand=d, surplus=s),
graph = g, PT = PT, S0 = S0, demand = d, surplus = s
)
# ==== 10) Identificar mejor resultado ====
all_costs <- sapply(results, function(x) x$best_cost)
best_idx <- which.min(all_costs)
best_res <- results[[best_idx]]
# ---- obtener valores detallados ----
best_detail <- objective_distance_extended(best_res$best_route, g, PT, S0, d, s,
minutes_per_block, cost_per_min_eur,
penalty_per_unit)
cat("\n=== MEJOR RESULTADO ===\n")
cat("Método:", best_res$method, "\n")
cat("Ruta óptima:\nPT ->", paste(best_res$best_route, collapse = " -> "), "-> PT\n")
cat("Distancia total (bloques):", round(best_detail$distance_blocks, 2), "\n")
cat("Tiempo estimado (min):", round(best_detail$time_minutes, 2), "\n")
cat("Coste operativo (€):", round(best_detail$cost_eur, 2), "\n")
cat("Penalización aplicada (bloques):", round(best_detail$penalty_blocks, 2), "\n")
# ==== 11) Graficar mejor ruta ====
plot_best_route(g, route = best_res$best_route, PT = PT, coords = coords,
color_route = "darkred")
# ==== 12) Exportar resultados ====
# ================================================================
# Crear summary_df con información extendida (sin exportar a CSV)
# ================================================================
summary_df <- data.frame(
Method = sapply(results, function(x) x$method),
Distance_Blocks = round(sapply(results, function(x) x$best_cost), 2),
Time_Seconds = round(sapply(results, function(x) x$time_secs), 3),
Time_Min = round(sapply(results, function(x)
objective_distance_extended(
x$best_route, g, PT, S0, d, s,
minutes_per_block, cost_per_min_eur, penalty_per_unit
)$time_minutes), 2),
Cost_EUR = round(sapply(results, function(x)
objective_distance_extended(
x$best_route, g, PT, S0, d, s,
minutes_per_block, cost_per_min_eur, penalty_per_unit
)$cost_eur), 2),
Penalty_Blocks = round(sapply(results, function(x)
objective_distance_extended(
x$best_route, g, PT, S0, d, s,
minutes_per_block, cost_per_min_eur, penalty_per_unit
)$penalty_blocks), 2),
Route = sapply(results, function(x)
paste(x$best_route, collapse = " -> "))
)
cat("\n=== SUMMARY OF RESULTS (EXTENDED) ===\n")
print(summary_df)
# ============================
# 0) Load required modules
# ============================
library(genalg)
library(DEoptim)
library(pso)
setwd("C:/Users/leodo/OneDrive/Escritorio/optimization/third delivery/OBA-II-Final-Proyect")
source("main_Data.R")
source("stations.R")
source("demand_supply.R")
source("graph_utils.R")
source("class_algorithms.R")
# ============================
# 1) Prepare graph + variables
# ============================
mapping_data <- make_mapping(all_names, N_OUTER)
outer_abbr <- mapping_data$outer_abbr
PT <- mapping_data$PT
g_data <- make_graph_with_weights(outer_abbr, PT)
g <- g_data$g
coords <- g_data$coords
minutes_per_block <- 2
E(g)$time_weight <- E(g)$weight * minutes_per_block
ds <- build_demand_supply(outer_abbr, N_OUTER, N_SURPLUS, PT)
d <- ds$demand
s <- ds$surplus
objective_numeric <- function(route, graph, PT, S0, demand, surplus,
minutes_per_block = 2, cost_per_min_eur = 0.6,
penalty_per_unit = 0.5) {
res <- objective_distance_extended(route, graph, PT, S0, demand, surplus,
minutes_per_block, cost_per_min_eur,
penalty_per_unit)
return(res$distance_blocks)
}
eval_fun <- function(route)
objective_numeric(route, graph = g, PT = PT, S0 = S0, demand = d,
surplus = s)
# ============================
# 2) Wrapper for running algorithms
# ============================
run_one_GA <- function() {
res <- ga_search(
outer_abbr = outer_abbr, fn = eval_fun,
graph = g, PT = PT, S0 = S0, demand = d,
surplus = s, penalty_per_unit = 0.5
)
list(best = res$best_cost, history = res$history, time = res$time_secs)
}
run_one_DE <- function() {
res <- de_search(
outer_abbr = outer_abbr, fn = eval_fun,
graph = g, PT = PT, S0 = S0, demand = d,
surplus = s, penalty_per_unit = 0.5
)
list(best = res$best_cost, history = res$history, time = res$time_secs)
}
run_one_PSO <- function() {
res <- pso_search(
outer_abbr = outer_abbr, fn = eval_fun,
graph = g, PT = PT, S0 = S0, demand = d,
surplus = s, penalty_per_unit = 0.5
)
list(best = res$best_cost, history = res$history, time = res$time_secs)
}
# ============================
# 3) RUN EXPERIMENTS
# ============================
Runs <- 30       # número de corridas por método
max_iters <- 100 # valor estándar para alinear gráficos
GA_hist <- matrix(NA, nrow = Runs, ncol = max_iters)
DE_hist <- matrix(NA, nrow = Runs, ncol = max_iters)
PSO_hist <- matrix(NA, nrow = Runs, ncol = max_iters)
GA_best <- numeric(Runs)
DE_best <- numeric(Runs)
PSO_best <- numeric(Runs)
GA_time <- numeric(Runs)
DE_time <- numeric(Runs)
PSO_time <- numeric(Runs)
for (i in 1:Runs) {
cat(sprintf("\n--- RUN %d OF %d ---\n", i, Runs))
ga <- run_one_GA()
de <- run_one_DE()
pso <- run_one_PSO()
GA_hist[i, ] <- head(ga$history, max_iters)
DE_hist[i, ] <- head(de$history, max_iters)
PSO_hist[i, ] <- head(pso$history, max_iters)
GA_best[i] <- ga$best
DE_best[i] <- de$best
PSO_best[i] <- pso$best
GA_time[i] <- ga$time
DE_time[i] <- de$time
PSO_time[i] <- pso$time
}
# ============================
# 0) Load required modules
# ============================
library(genalg)
library(DEoptim)
library(pso)
setwd("C:/Users/leodo/OneDrive/Escritorio/optimization/third delivery/OBA-II-Final-Proyect")
source("main_Data.R")
source("stations.R")
source("demand_supply.R")
source("graph_utils.R")
source("class_algorithms.R")
# ============================
# 1) Prepare graph + variables
# ============================
mapping_data <- make_mapping(all_names, N_OUTER)
outer_abbr <- mapping_data$outer_abbr
PT <- mapping_data$PT
g_data <- make_graph_with_weights(outer_abbr, PT)
g <- g_data$g
coords <- g_data$coords
minutes_per_block <- 2
E(g)$time_weight <- E(g)$weight * minutes_per_block
ds <- build_demand_supply(outer_abbr, N_OUTER, N_SURPLUS, PT)
d <- ds$demand
s <- ds$surplus
objective_numeric <- function(route, graph, PT, S0, demand, surplus,
minutes_per_block = 2, cost_per_min_eur = 0.6,
penalty_per_unit = 0.5) {
res <- objective_distance_extended(route, graph, PT, S0, demand, surplus,
minutes_per_block, cost_per_min_eur,
penalty_per_unit)
return(res$distance_blocks)
}
eval_fun <- function(route, ...) {
objective_numeric(
route,
graph = g, PT = PT, S0 = S0,
demand = d, surplus = s
)
}
# ============================
# 2) Wrapper for running algorithms
# ============================
run_one_GA <- function() {
res <- ga_search(
outer_abbr = outer_abbr, fn = eval_fun,
graph = g, PT = PT, S0 = S0, demand = d,
surplus = s, penalty_per_unit = 0.5
)
list(best = res$best_cost, history = res$history, time = res$time_secs)
}
run_one_DE <- function() {
res <- de_search(
outer_abbr = outer_abbr, fn = eval_fun,
graph = g, PT = PT, S0 = S0, demand = d,
surplus = s, penalty_per_unit = 0.5
)
list(best = res$best_cost, history = res$history, time = res$time_secs)
}
run_one_PSO <- function() {
res <- pso_search(
outer_abbr = outer_abbr, fn = eval_fun,
graph = g, PT = PT, S0 = S0, demand = d,
surplus = s, penalty_per_unit = 0.5
)
list(best = res$best_cost, history = res$history, time = res$time_secs)
}
# ============================
# 3) RUN EXPERIMENTS
# ============================
Runs <- 30       # número de corridas por método
max_iters <- 100 # valor estándar para alinear gráficos
GA_hist <- matrix(NA, nrow = Runs, ncol = max_iters)
DE_hist <- matrix(NA, nrow = Runs, ncol = max_iters)
PSO_hist <- matrix(NA, nrow = Runs, ncol = max_iters)
GA_best <- numeric(Runs)
DE_best <- numeric(Runs)
PSO_best <- numeric(Runs)
GA_time <- numeric(Runs)
DE_time <- numeric(Runs)
PSO_time <- numeric(Runs)
for (i in 1:Runs) {
cat(sprintf("\n--- RUN %d OF %d ---\n", i, Runs))
ga <- run_one_GA()
de <- run_one_DE()
pso <- run_one_PSO()
GA_hist[i, ] <- head(ga$history, max_iters)
DE_hist[i, ] <- head(de$history, max_iters)
PSO_hist[i, ] <- head(pso$history, max_iters)
GA_best[i] <- ga$best
DE_best[i] <- de$best
PSO_best[i] <- pso$best
GA_time[i] <- ga$time
DE_time[i] <- de$time
PSO_time[i] <- pso$time
}
# ============================
# 0) Load required modules
# ============================
library(genalg)
library(DEoptim)
library(pso)
setwd("C:/Users/leodo/OneDrive/Escritorio/optimization/third delivery/OBA-II-Final-Proyect")
source("main_Data.R")
source("stations.R")
source("demand_supply.R")
source("graph_utils.R")
source("class_algorithms.R")
# ============================
# 1) Prepare graph + variables
# ============================
mapping_data <- make_mapping(all_names, N_OUTER)
outer_abbr <- mapping_data$outer_abbr
PT <- mapping_data$PT
g_data <- make_graph_with_weights(outer_abbr, PT)
g <- g_data$g
coords <- g_data$coords
minutes_per_block <- 2
E(g)$time_weight <- E(g)$weight * minutes_per_block
ds <- build_demand_supply(outer_abbr, N_OUTER, N_SURPLUS, PT)
d <- ds$demand
s <- ds$surplus
objective_numeric <- function(route, graph, PT, S0, demand, surplus,
minutes_per_block = 2, cost_per_min_eur = 0.6,
penalty_per_unit = 0.5) {
res <- objective_distance_extended(route, graph, PT, S0, demand, surplus,
minutes_per_block, cost_per_min_eur,
penalty_per_unit)
return(res$distance_blocks)
}
eval_fun <- function(route, ...) {
objective_numeric(
route,
graph = g, PT = PT, S0 = S0,
demand = d, surplus = s
)
}
# ============================
# 2) Wrapper for running algorithms
# ============================
run_one_GA <- function() {
res <- ga_search(
outer_abbr = outer_abbr, fn = eval_fun,
graph = g, PT = PT, S0 = S0, demand = d,
surplus = s, penalty_per_unit = 0.5
)
list(best = res$best_cost, history = res$history, time = res$time_secs)
}
run_one_DE <- function() {
res <- de_search(
outer_abbr = outer_abbr, fn = eval_fun,
graph = g, PT = PT, S0 = S0, demand = d,
surplus = s, penalty_per_unit = 0.5
)
list(best = res$best_cost, history = res$history, time = res$time_secs)
}
run_one_PSO <- function() {
res <- pso_search(
outer_abbr = outer_abbr, fn = eval_fun,
graph = g, PT = PT, S0 = S0, demand = d,
surplus = s, penalty_per_unit = 0.5
)
list(best = res$best_cost, history = res$history, time = res$time_secs)
}
# ============================
# 3) RUN EXPERIMENTS
# ============================
Runs <- 10       # número de corridas por método
max_iters <- 25 # valor estándar para alinear gráficos
GA_hist <- matrix(NA, nrow = Runs, ncol = max_iters)
DE_hist <- matrix(NA, nrow = Runs, ncol = max_iters)
PSO_hist <- matrix(NA, nrow = Runs, ncol = max_iters)
GA_best <- numeric(Runs)
DE_best <- numeric(Runs)
PSO_best <- numeric(Runs)
GA_time <- numeric(Runs)
DE_time <- numeric(Runs)
PSO_time <- numeric(Runs)
# === Function to pad convergence vectors ===
pad_history <- function(vec, max_len) {
n <- length(vec)
if (n >= max_len) return(vec[1:max_len])
c(vec, rep(tail(vec, 1), max_len - n))
}
for (i in 1:Runs) {
cat(sprintf("\n--- RUN %d OF %d ---\n", i, Runs))
ga <- run_one_GA()
de <- run_one_DE()
pso <- run_one_PSO()
GA_hist[i, ] <- pad_history(ga$history, max_iters)
DE_hist[i, ] <- pad_history(de$history, max_iters)
PSO_hist[i, ] <- pad_history(pso$history, max_iters)
GA_best[i] <- ga$best
DE_best[i] <- de$best
PSO_best[i] <- pso$best
GA_time[i] <- ga$time
DE_time[i] <- de$time
PSO_time[i] <- pso$time
}
# ============================
# 4) AGGREGATED STATISTICS
# ============================
avg_GA <- colMeans(GA_hist, na.rm = TRUE)
avg_DE <- colMeans(DE_hist, na.rm = TRUE)
avg_PSO <- colMeans(PSO_hist, na.rm = TRUE)
cat("\n===== AVERAGE BEST VALUES =====\n")
print(c(GA = mean(GA_best), DE = mean(DE_best), PSO = mean(PSO_best)))
cat("\n===== AVERAGE TIMES (sec) =====\n")
print(c(GA = mean(GA_time), DE = mean(DE_time), PSO = mean(PSO_time)))
# ============================
# 5) PLOT COMPARISON
# ============================
plot(avg_GA, type="l", lwd=3, col="blue",
ylim = range(c(avg_GA, avg_DE, avg_PSO)),
xlab="Iteration", ylab="Average best",
main="Average Convergence (GA, DE, PSO)")
lines(avg_DE, lwd=3, col="darkgreen")
lines(avg_PSO, lwd=3, col="red")
legend("topright", legend=c("GA", "DE", "PSO"),
col=c("blue", "darkgreen", "red"), lwd=3)
# ============================
# 6) Export results
# ============================
comp_results <- data.frame(
Method = c("GA", "DE", "PSO"),
Avg_Best = c(mean(GA_best), mean(DE_best), mean(PSO_best)),
Avg_Time = c(mean(GA_time), mean(DE_time), mean(PSO_time)),
Var_Best = c(var(GA_best), var(DE_best), var(PSO_best))
)
print(comp_results)
# =========================================================
# stats_algorithms.R — Statistical comparison of GA, DE, PSO
# Based on rubric point 6 (10% of grade)
# =========================================================
# --- Load compare results (replace with your path if needed) ---
# Assumes you ran `compare_algorithms.R` FIRST
# and have GA_best, DE_best, PSO_best in memory.
if (!exists("GA_best") | !exists("DE_best") | !exists("PSO_best")) {
stop("Error: GA_best, DE_best, PSO_best not found. Run compare_algorithms.R first.")
}
# --- Create data frame for analysis ---
df <- data.frame(
value = c(GA_best, DE_best, PSO_best),
method = factor(rep(c("GA", "DE", "PSO"),
each = length(GA_best)))
)
cat("\n===== DATA SUMMARY =====\n")
print(aggregate(value ~ method, df, summary))
# =========================================================
# 1) ANOVA TEST (Parametric)
# =========================================================
cat("\n===== ANOVA TEST =====\n")
anova_res <- aov(value ~ method, data = df)
print(summary(anova_res))
# Check normality of residuals
shapiro_res <- shapiro.test(residuals(anova_res))
cat("\nShapiro-Wilk normality test on residuals:\n")
print(shapiro_res)
# Check homogeneity of variances
levene_test <- car::leveneTest(value ~ method, df)
# =========================================================
# stats_algorithms.R — Statistical comparison of GA, DE, PSO
# Based on rubric point 6 (10% of grade)
# ==================
install.packages("car")
library(car)
if (!exists("GA_best") | !exists("DE_best") | !exists("PSO_best")) {
stop("Error: GA_best, DE_best, PSO_best not found. Run compare_algorithms.R first.")
}
# --- Create data frame for analysis ---
df <- data.frame(
value = c(GA_best, DE_best, PSO_best),
method = factor(rep(c("GA", "DE", "PSO"),
each = length(GA_best)))
)
cat("\n===== DATA SUMMARY =====\n")
print(aggregate(value ~ method, df, summary))
# =========================================================
# 1) ANOVA TEST (Parametric)
# =========================================================
cat("\n===== ANOVA TEST =====\n")
anova_res <- aov(value ~ method, data = df)
print(summary(anova_res))
# Check normality of residuals
shapiro_res <- shapiro.test(residuals(anova_res))
cat("\nShapiro-Wilk normality test on residuals:\n")
print(shapiro_res)
# Check homogeneity of variances
levene_test <- car::leveneTest(value ~ method, df)
cat("\nLevene Test for homogeneity of variances:\n")
print(levene_test)
# =========================================================
# 2) KRUSKAL–WALLIS (non-parametric alternative)
# =========================================================
cat("\n===== KRUSKAL–WALLIS TEST =====\n")
kw <- kruskal.test(value ~ method, df)
print(kw)
# =========================================================
# 3) PAIRWISE WILCOXON TESTS (non-parametric pairwise)
# =========================================================
cat("\n===== PAIRWISE WILCOXON TESTS =====\n")
wilc <- pairwise.wilcox.test(df$value, df$method,
p.adjust.method = "bonferroni")
print(wilc)
# =========================================================
# 4) PAIRWISE t-TESTS (parametric pairwise)
# =========================================================
cat("\n===== PAIRWISE t-TESTS =====\n")
t <- pairwise.t.test(df$value, df$method,
p.adjust.method = "bonferroni")
print(t)
# =========================================================
# 5) AUTOMATIC INTERPRETATION
# =========================================================
cat("\n===== INTERPRETATION (AUTO-GENERATED) =====\n")
interpret <- function(anova_res, kw_res, t_res, wilcox_res) {
# Detect significance
sig_anova  <- summary(anova_res)[[1]][["Pr(>F)"]][1] < 0.05
sig_kw     <- kw_res$p.value < 0.05
cat("\n--- Global Tests ---\n")
if (sig_anova) {
cat("ANOVA: Significant differences detected between GA, DE, PSO (p < 0.05).\n")
} else {
cat("ANOVA: No significant differences between GA, DE, PSO.\n")
}
if (sig_kw) {
cat("Kruskal–Wallis: Significant differences detected (p < 0.05).\n")
} else {
cat("Kruskal–Wallis: No significant differences found.\n")
}
cat("\n--- Pairwise Comparisons ---\n")
# Pairwise t-tests
cat("\nPairwise t-tests (Bonferroni-adjusted):\n")
print(t_res$p.value)
# Pairwise Wilcoxon tests
cat("\nPairwise Wilcoxon tests (Bonferroni-adjusted):\n")
print(wilcox_res$p.value)
cat("\n--- Summary Interpretation ---\n")
# Determine best method
best_means <- tapply(df$value, df$method, mean)
best_method <- names(which.min(best_means))
cat(sprintf("Mean performance (lower = better): GA = %.2f, DE = %.2f, PSO = %.2f\n",
best_means["GA"], best_means["DE"], best_means["PSO"]))
cat(sprintf("Best overall method: %s\n", best_method))
cat("\nInterpretation:\n")
if (sig_kw | sig_anova) {
cat(sprintf("There are statistically significant differences between at least two algorithms.\n%s appears to outperform the others on average.\n",
best_method))
} else {
cat("There are NO statistically significant differences between the algorithms.\nThey perform similarly.\n")
}
}
interpret(anova_res, kw, t, wilc)
